{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYl5vWB09IBj"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d manjilkarki/deepfake-and-real-images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjxR8r5b9UDV"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/deepfake-and-real-images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLGGCBii9VGS",
        "outputId": "32802050-ddb0-4962-f4e5-8bdaf832495f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 140002 images belonging to 2 classes.\n",
            "Found 39428 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "Datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "Train_generator = Datagen.flow_from_directory(\n",
        "    \"/kaggle/input/deepfake-and-real-images/Dataset/Train\",\n",
        "    target_size = (224,224),\n",
        "    batch_size = 64,\n",
        "    class_mode = \"binary\",\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "Valid_generator = Datagen.flow_from_directory(\n",
        "    \"/kaggle/input/deepfake-and-real-images/Dataset/Validation\",\n",
        "    target_size = (224,224),\n",
        "    batch_size = 64,\n",
        "    class_mode = \"binary\",\n",
        "    shuffle = True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHoQHgx9y7DR"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, add, BatchNormalization, Dropout, GlobalAveragePooling2D, add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "model = InceptionV3(\n",
        "    include_top = False,\n",
        "    weights = \"imagenet\",\n",
        "    input_shape = (224,224,3)\n",
        ")\n",
        "\n",
        "for layer in model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Get the output of the InceptionV3 model\n",
        "x = model.output\n",
        "\n",
        "# Add new layers on top of the InceptionV3 output\n",
        "x = GlobalAveragePooling2D()(x)  # Global Average Pooling\n",
        "x = Dense(128, activation='relu', kernel_regularizer=l2(0.05))(x)  # Dense layer with 128 units\n",
        "x = BatchNormalization()(x)  # Batch Normalization\n",
        "x = Dropout(0.5)(x)  # Dropout layer with 50% dropout rate\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.05))(x)  # Dense layer with 64 units\n",
        "x = BatchNormalization()(x)  # Batch Normalization\n",
        "x = Dropout(0.5)(x)  # Dropout layer with 50% dropout rate\n",
        "x = Dense(1, activation='sigmoid')(x)  # Output layer with sigmoid activation\n",
        "\n",
        "# Create a new model with the specified inputs and outputs\n",
        "model = Model(inputs=model.input, outputs=x)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOXodoYjBcpF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# import precision, Recall\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "# from tensorflow_addons.metrics import F1Score  # If using TensorFlow Addons\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0005),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\", Precision(), Recall()]\n",
        ")\n",
        "# Callbacks\n",
        "earlystopping = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    verbose=1,\n",
        "    patience = 3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "modelcheckpoint = ModelCheckpoint(\n",
        "    \"model.keras\",\n",
        "    monitor=\"val_loss\",\n",
        "    verbose=1,\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.2,\n",
        "    verbose=1,\n",
        "    min_lr=1e-6,\n",
        "    patience = 1\n",
        ")\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    Train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=Valid_generator,\n",
        "    verbose=1,\n",
        "    callbacks=[earlystopping, modelcheckpoint, reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y27ChJ-eLi_0"
      },
      "outputs": [],
      "source": [
        "# Visulaize\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history[\"loss\"], label = \"Train Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label = \"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQDFQ2XVLvg9"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"accuracy\"], label = \"Train Accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label = \"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-I1UeEQHFtc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Prepare the test data generator\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    \"/kaggle/input/deepfake-and-real-images/Dataset/Test\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',  # Binary classification\n",
        "    shuffle=False  # Important for preserving the order of labels\n",
        ")\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_classes = (predictions > 0.5).astype(int).flatten()  # Convert probabilities to class labels\n",
        "\n",
        "# Get the true labels\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "# Calculate confusion matrix and classification report\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "report = classification_report(true_classes, predicted_classes, target_names=['Fake', 'Real'])\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Assuming you already have true_classes and predicted_classes from your model\n",
        "f1 = f1_score(true_classes, predicted_classes)\n",
        "print(\"F1 Score:\", f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kY_htgQfXGYt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}